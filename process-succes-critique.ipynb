{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd00d1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      budget                                    genres original_language  \\\n",
      "0  237000000  Action Adventure Fantasy Science Fiction                en   \n",
      "1  300000000                  Adventure Fantasy Action                en   \n",
      "2  245000000                    Action Adventure Crime                en   \n",
      "3  250000000               Action Crime Drama Thriller                en   \n",
      "4  260000000          Action Adventure Science Fiction                en   \n",
      "\n",
      "   popularity                               production_companies  \\\n",
      "0  150.437577  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
      "1  139.082615  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
      "2  107.376788  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
      "3  112.312950  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
      "4   43.926995        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
      "\n",
      "                                production_countries     revenue  runtime  \\\n",
      "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...  2787965087    162.0   \n",
      "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   961000000    169.0   \n",
      "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   880674609    148.0   \n",
      "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...  1084939099    165.0   \n",
      "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   284139100    132.0   \n",
      "\n",
      "                                    spoken_languages  vote_average  \\\n",
      "0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...           7.2   \n",
      "1           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]           6.9   \n",
      "2  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...           6.3   \n",
      "3           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]           7.6   \n",
      "4           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]           6.1   \n",
      "\n",
      "   vote_count                                               cast  \\\n",
      "0       11800  Sam Worthington Zoe Saldana Sigourney Weaver S...   \n",
      "1        4500  Johnny Depp Orlando Bloom Keira Knightley Stel...   \n",
      "2        4466  Daniel Craig Christoph Waltz L\\u00e9a Seydoux ...   \n",
      "3        9106  Christian Bale Michael Caine Gary Oldman Anne ...   \n",
      "4        2124  Taylor Kitsch Lynn Collins Samantha Morton Wil...   \n",
      "\n",
      "            director  \n",
      "0      James Cameron  \n",
      "1     Gore Verbinski  \n",
      "2         Sam Mendes  \n",
      "3  Christopher Nolan  \n",
      "4     Andrew Stanton  \n"
     ]
    }
   ],
   "source": [
    "#Ici , on va étudier le succes critique a travers des critiques et des notes attribuées aux films\n",
    "\n",
    "#On va d'abord charger le dataset original\n",
    "import pandas as pd\n",
    "df = pd.read_csv('movie_dataset_cleaned_final.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01589f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vote_average  critique_success\n",
      "0           7.2                 1\n",
      "1           6.9                 1\n",
      "2           6.3                 1\n",
      "3           7.6                 1\n",
      "4           6.1                 1\n"
     ]
    }
   ],
   "source": [
    "#Maintenant on va le transformer en dataset supervisé pour un apprentissage machine-learning\n",
    "#On ajoute une colonne \"critique_success\" qui vaut 1 si la note moyenne est supérieure à la moyenne générale des notes\n",
    "df['critique_success'] = (df['vote_average'] > df['vote_average'].mean()).astype(int)\n",
    "print(df[['vote_average', 'critique_success']].head())\n",
    "#On sauvegarde le nouveau dataset\n",
    "df.to_csv('movie_dataset_supervised_critique.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3788c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      budget original_language  popularity     revenue  runtime  vote_average  \\\n",
      "0  237000000                en  150.437577  2787965087    162.0           7.2   \n",
      "1  300000000                en  139.082615   961000000    169.0           6.9   \n",
      "2  245000000                en  107.376788   880674609    148.0           6.3   \n",
      "3  250000000                en  112.312950  1084939099    165.0           7.6   \n",
      "4  260000000                en   43.926995   284139100    132.0           6.1   \n",
      "\n",
      "   vote_count           director  critique_success  \n",
      "0       11800      James Cameron                 1  \n",
      "1        4500     Gore Verbinski                 1  \n",
      "2        4466         Sam Mendes                 1  \n",
      "3        9106  Christopher Nolan                 1  \n",
      "4        2124     Andrew Stanton                 1  \n"
     ]
    }
   ],
   "source": [
    "#Maintenant on va supprimer les colonnes inutiles pour l'apprentissage supervisé\n",
    "df = df.drop(columns=['genres', 'production_companies', 'production_countries', 'spoken_languages', 'cast'])\n",
    "print(df.head())\n",
    "#On sauvegarde le dataset nettoyé\n",
    "df.to_csv('movie_dataset_supervised_critique_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c20e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Results:\n",
      "Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021    0]\n",
      " [   0 1381]]\n",
      "Nombre de prédictions correctes: 2402 sur 2402\n",
      "Précision du modèle: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement du dataset nettoyé\n",
    "df = pd.read_csv('movie_dataset_supervised_critique_cleaned.csv')\n",
    "\n",
    "# Features / target\n",
    "X = df[['budget', 'original_language', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'director']]\n",
    "y = df['critique_success']\n",
    "\n",
    "# Colonnes\n",
    "categorical_cols = ['original_language', 'director']\n",
    "numeric_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline finale\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Decision Tree Classifier Results:\")\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Score du modèle\n",
    "correct_predictions = (y_test == y_pred).sum()\n",
    "total_predictions = y_test.shape[0]\n",
    "print(f\"Nombre de prédictions correctes: {correct_predictions} sur {total_predictions}\")\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Précision du modèle: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b706118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Results:\n",
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1021\n",
      "           1       1.00      1.00      1.00      1381\n",
      "\n",
      "    accuracy                           1.00      2402\n",
      "   macro avg       1.00      1.00      1.00      2402\n",
      "weighted avg       1.00      1.00      1.00      2402\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1021    0]\n",
      " [   0 1381]]\n",
      "\n",
      "Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Imports ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# --- 2. Chargement du dataset ---\n",
    "df = pd.read_csv('movie_dataset_supervised_critique_cleaned.csv')\n",
    "\n",
    "# --- 3. Features / Target ---\n",
    "X = df[['budget', 'original_language', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'director']]\n",
    "y = df['critique_success']\n",
    "\n",
    "# --- 4. Colonnes numériques / catégoriques ---\n",
    "categorical_cols = ['original_language', 'director']\n",
    "numeric_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "# --- 5. Préprocessing ---\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- 6. Pipeline avec Forêt Aléatoire ---\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=100,       # nombre d'arbres\n",
    "        max_depth=None,        # profondeur illimitée\n",
    "        random_state=42,\n",
    "        n_jobs=-1              # utilise tous les cœurs CPU\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- 7. Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# --- 8. Entraînement ---\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- 9. Prédictions ---\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# --- 10. Évaluation ---\n",
    "print(\"Random Forest Classifier Results:\")\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Score de précision\n",
    "correct_predictions = (y_test == y_pred).sum()\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184e817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier Results:\n",
      "Accuracy: 0.50\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.84      0.59      1017\n",
      "           1       0.68      0.25      0.36      1369\n",
      "\n",
      "    accuracy                           0.50      2386\n",
      "   macro avg       0.57      0.55      0.48      2386\n",
      "weighted avg       0.58      0.50      0.46      2386\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 856  161]\n",
      " [1028  341]]\n",
      "\n",
      "Model Accuracy: 0.50\n",
      "Nombre de prédictions correctes: 1197 sur 2386\n"
     ]
    }
   ],
   "source": [
    "# Appliquons le classifieur bayésien (Naive Bayes)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement du dataset nettoyé\n",
    "df = pd.read_csv('movie_dataset_supervised_critique_cleaned.csv')\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# Features / target\n",
    "X = df[['budget', 'original_language', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'director']]\n",
    "y = df['critique_success']\n",
    "\n",
    "# Colonnes catégoriques et numériques\n",
    "categorical_cols = ['original_language', 'director']\n",
    "numeric_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "# Preprocessing pour les colonnes numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Preprocessing pour les colonnes catégoriques\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combinaison des transformateurs\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline finale avec le classificateur Naive Bayes\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GaussianNB())\n",
    "])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Gaussian Naive Bayes Classifier Results:\")\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Score du modèle\n",
    "correct_predictions = (y_test == y_pred).sum()\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "print(f'Nombre de prédictions correctes: {correct_predictions} sur {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1150b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier Results:\n",
      "Accuracy: 0.60\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.47      0.51      1017\n",
      "           1       0.64      0.70      0.67      1369\n",
      "\n",
      "    accuracy                           0.60      2386\n",
      "   macro avg       0.59      0.59      0.59      2386\n",
      "weighted avg       0.60      0.60      0.60      2386\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[482 535]\n",
      " [409 960]]\n",
      "\n",
      "Model Accuracy: 0.60\n",
      "Nombre de prédictions correctes: 1442 sur 2386\n"
     ]
    }
   ],
   "source": [
    "# Appliquons K-Nearest Neighbors (KNN)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Chargement du dataset nettoyé\n",
    "df = pd.read_csv('movie_dataset_supervised_critique_cleaned.csv')\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "df = df.dropna()\n",
    "\n",
    "# Features / target\n",
    "X = df[['budget', 'original_language', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count', 'director']]\n",
    "y = df['critique_success']\n",
    "\n",
    "# Colonnes catégoriques et numériques\n",
    "categorical_cols = ['original_language', 'director']\n",
    "numeric_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "# Preprocessing pour les colonnes numériques\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Preprocessing pour les colonnes catégoriques\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combinaison des transformateurs\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline finale avec le classificateur KNN\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"K-Nearest Neighbors Classifier Results:\")\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Score du modèle\n",
    "correct_predictions = (y_test == y_pred).sum()\n",
    "accuracy = correct_predictions / len(y_test)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.2f}\")\n",
    "print(f'Nombre de prédictions correctes: {correct_predictions} sur {len(y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
